\chapter{Model}
\label{model}
\thispagestyle{empty}

In this chapter we describe the derivation of our proposed model. We give again the original formulation of GAN for completeness and then proceed with the related work that lay the necessary steps to our model. We indicate the conditions and assumptions necessary for the model and end with several research questions that we address in chapter \ref{appendiceB} through empirical results.

\section{From GAN to RS}
\label{from_gan_to_rs}
Generative Adversarial Networks \cite{goodfellow2014generative} are now ubiquitous in the Computer Vision domain due to their generative modeling abilities. GANs learn implicitly a probability distribution by being able to generate samples in the data space from a noise input $\textbf{z}$ sampled from a predefined distribution $p(\textbf{z})$. As introduced in \ref{appendiceA}, GANs are composed of two players, usually two neural networks that play a \emph{minimax} zero-sum game in order to learn a target distribution. The objective function that these two networks optimize as given by \cite{goodfellow2014generative} is shown below:
\[
    \min_{G} \max_{D} \E_{x\sim{p_{data}(x)}} [log \, D(x)] + \E_{z\sim{p_{\boldsymbol{z}}(z)}} \big[log\big(1-D(G(z))\big)\big]
\]
where the discriminator \emph{D} is a binary classifier with the well-known \emph{sigmoid} activation function:
\[
    D(x) = \frac{1}{1 + \exp(-x)}
\]
and the generator G is any neural network that maps noise input $z$ to the data space. As indicated in \ref{appendiceA} the generator network uses the gradient from the discriminator to update its weights and generate better samples to fool the discriminator. In Computer Vision the generator is usually tasked with producing complete images where each composing pixel of the image can take continuous values ranging from 0 to 255.

IRGAN \cite{wang2017irgan} was first to propose the application of GAN for information retrieval and RS. Differently from the original formulation, IRGAN uses the generator network to generate/select item $d$ (e.g. item ID) from a pool of items as the most relevant for a specific user. This generation process is different from applications of GANs in Computer vision because picking items consists in a \emph{discrete} sampling procedure. The objective function in IRGAN (in the context of information retrieval) is given as:
\[
    \begin{split}
        J^{G^*,D^*} = \min_{G} \max_{D} \sum_{n=1}^N\Big(
        & \E_{d \sim{p_{true}(d|q_{n},r)}}[log \, D(d|q_{n})] \: + \: \\
        & \E_{d \sim p_{\theta}(d|q_{n},r)}\big[log\big(1-D(d|q_{n})\big)\big]\Big)
    \end{split}
\]
where $q_{n}$ is a submitted query, $r$ is the relevance distribution of a user over items and $p_{\theta}(d|q_{n},r)$ is the generative model G characterized by parameters $\theta$ that learns to select document $d$ that are most relevant for the submitted query. Since the generator samples discrete values its update cannot be done through gradient descent so for this reason IRGAN uses the policy-gradient based reinforcement learning \cite{williams1992simple}.

CFGAN \cite{chae2018cfgan} brings forward a potential issue in the optimization problem of the discriminator of IRGAN. The aim of the algorithm is for the generator to be able to sample items that are most likely relevant for the user. Consider the beginning of the training procedure of IRGAN. Initially the discriminator has to differentiate between real item IDs and fake item IDs selected by the generator. This is easy in the beginning since the generator is not yet optimal so it will generate IDs that the discriminator can easily detect as not being relevant for the user. However, when approaching the optimality of the generator, the discriminator will be presented with item IDs that are identical to the ones already in the historical profile of the user but are presented to the discriminator labelled as \emph{real} (when the item ID is coming from the real training data) and \emph{fake} (when the item ID is coming from the generator) at the same time. CFGAN empirically shows that training IRGAN up to this point confuses the discriminator and deteriorates the accuracy of the algorithm.

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{model/irgan_problem1.png}
        \caption{IRGAN model in the first epochs of training. The items picked by the generator are different from the ground truth.}
        \label{fig:irgan_problem1}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{model/irgan_problem2.png}
        \caption{IRGAN model near/at optimal generator. The generator picks items with the label \emph{fake} identical to those in the training set which the discriminator has seen as \emph{real}.}
        \label{fig:irgan_problem2}
    \end{subfigure}
    \caption{Discrete item generation issue with IRGAN.}
    \label{fig:irgan_problem}
\end{figure}

To solve this problem CFGAN proposes a vector-wise training for RS where the generator G outputs \emph{real-valued} vectors. In this way D can discriminate between real user historical interactions and plausible historical interactions produced by G.

\section{GANMF}
\label{sec:GANMF}
Our model, which we denote as GANMF, attemps to solve the generic Top-N recommendation problem presented in \ref{appendiceA}. We take a model-based approach for the recommendations and structure GANMF as a matrix factorization model. We task our model to learn the distribution of historical interactions of each respective user utilizing the \emph{vector-training} introduced by CFGAN. This means for the generator to be able to produce historical profiles that are very similar to the training data but differ in such a way that can provide recommendations better than (comparable to) other MF-based baselines. GANMF follows the original GAN formulation and is composed of two players, a generator network G and a discriminator network D. GAN allow the modeling of \emph{multi-modal} outputs \cite{goodfellow2016nips} where for a specific input there might be multiple correct outputs or labels. For this reason the input of the generator in a GAN is usually some noise from a predefined distribution. By using this noise GANs can produce diverse samples that resemble the training data. However, in our case the recommendation must be deterministic and unique in order for it to provide the best user experience and make it feel personalized for the users. This urges the conditioning of the generation process on each user available in our training data.

\subsection{Discriminator D}
\label{sec:GANMF_D}
The discriminator in a GAN is used to differentiate the source of the data it takes as input. As mentioned in \ref{from_gan_to_rs} the discriminator is usually a binary classifier and in the original formulation it outputs the probability of the input being real and not generated by G. For GANMF we take another approach and model D according to the discriminator in EBGAN \cite{zhao2016energy}. As described in \ref{appendiceA}, EBGAN was first to introduce the discriminator as an energy function where is assigns low energy to samples in the data manifold and high energy elsewhere. In this context we can think of the energy function as a hyperplane which takes the shape of a valley near real data that come from the training set and takes the shape of mountains near data generated by G. Just like EBGAN, GANMF uses an autoencoder \cite{kramer1991nonlinear} as the discriminator where the reconstruction loss acts as the energy function:
\begin{equation}
    D(x) = \big\|Dec\big(Enc(x)\big) - x\big\|
    \label{eq:recon_loss}
\end{equation}
where $Enc(\cdot)$ and $Dec(\cdot)$ are the \emph{encoder} and \emph{decoder} functions and $||\cdot||$ is the Euclidean norm.

The rationale for using an autoencoder model as discriminator falls in the same line of the discussion by the authors of EBGAN. In the original formulation the discriminator's output is a scalar value squashed in the range $[0-1]$ by a \emph{sigmoid} activation indicating a probability. The output of the generator in the case of GANMF is very high dimensional; specifically it is the length of a user historical profile $|I|$, which for some datasets might be in thousands or even millions of dimensions. Updating the weights of the generator through the gradient of a single scalar value in the discriminator output poses difficulties for learning the generator. Consider the case when two generated historical profiles for the same user, $\hat{I^1_{u}}$ and $\hat{I^2_{u}}$, differ between each other a lot but for the discriminator they are both fake profiles. The gradient propagated back to update the weights is going to be more or less the same for both generated profiles. Assuming $I^*_{u}$ to be the optimal generated profile for user $u$ then under some distance metric (e.g. Euclidean distance) we have:
\[
||I^*_{u} - \hat{I^1_{u}}|| \leq  ||I^*_{u} - \hat{I^2_{u}}||\quad \bigvee \quad
||I^*_{u} - \hat{I^2_{u}}|| \leq  ||I^*_{u} - \hat{I^1_{u}}||
\]
yet the gradient coming from the discriminator will not make this distinction very clear. Also when training through Mini Batch Gradient Descent, having a single value output makes the gradient for the batch highly unlikely to be orthogonal for the individual batch samples \cite{zhao2016energy}. We further explore the effect of the autoencoder as the discriminator through experiments.

Given a real data $x$ and a user conditioning vector $y$ (more on this in \ref{sec:GANMF_G}) the loss function for GANMF discriminator is given by the \emph{hinge loss} \cite{zhao2016energy}:
\begin{equation}
    \mathcal{L}_{D}(x, y) = D(x) + \big[m - D\big(G(y)\big)\big]^{+} + \lambda_{D} \|\Omega^{D}\|^{2}_{2}
    \label{eq:dloss}
\end{equation}
where $[\cdot]^+ = \max (0, \cdot)$, $m$ is a positive margin, $D(\cdot)$ is the autoencoder reconstruction loss as defined in (\ref{eq:recon_loss}), $G(\cdot)$ is the generator function, $\lambda_{D}$ is a regularization constant and $\Omega^{D}$ is the set of parameters of the discriminator.
D (the discriminator, not the $D(\cdot)$ function) is trained to minimize \ref{eq:dloss}. The first term denotes the reconstruction error of the autoencoder on real user profiles. Since the reconstruction error is always positive the minimum of this term is 0 meaning a perfect reconstruction. The second term involving the $\max$ operator can be summarized as:
\[
    \big[m - D\big(G(y)\big)\big]^+ = \max \Big(0, D\big(G(y)\big)\Big) = 
    \begin{cases}
        0 & D\big(G(y)\big) \geq m \\
        m - D\big(G(y)\big) & D\big(G(y)\big) < m
    \end{cases}
\]
This term tries to keep the reconstruction loss of generated user profiles above the margin value. Since the discriminator is trying to minimize this term also, the autoencoder's weights are updated in such a way as to prevent the reconstruction error falling below the margin otherwise it is penalized by how much the error violates it. If the reconstruction loss is more than the margin, the second term reaches its minimum at 0. Using the $\max$ operator we achieve a higher energy value for the generated user profiles. This operator is common in training Support Vector Machines where optimal class-separating hyperplane is the one that does not violate the margin from the support vectors \cite{cortes1995support}. In GANMF $m$ is a hyperparameter of the model which we tune through a hold-out validation set.

The last term of $\mathcal{L}_{D}$ is a \emph{$L_{2}$ regularization term} on the parameters of the discriminator that helps prevent overfitting.

\subsection{Generator G}
\label{sec:GANMF_G}
We now detail the generator network. As stated in section \ref{sec:GANMF}, we construct G as a conditional generator by using as condition attributes that are unique to each user. These attributes serve as the only input to a fully-connected neural network. In \cite{strub2016hybrid} the authors show that a single layer autoencoder with linear activation function in the output layer is very similar to a low-rank MF approach. Following this observation, we use only one hidden layer for the generator. This is an embedding layer that takes the user conditioning vector as input and constructs a representation out of it. We set the dimension of this layer to the number of latent factors for our MF-based model. Since the conditioning vector will be deterministic and unique for each user, the output of the hidden layer will act as a representation of the user, namely his/her latent factors. The output layer of the generator will have the same dimension as the length of a user historical profile, $|I|$. 

Let us consider a single-layer fully-connected neural network (see figure \ref{fig:generator_MF}). The first layer $l^0$ represents the input, the user conditioning vector in the GANMF case. The nodes in this layer are all connected to the nodes in the hidden layer $l^1$ which represents the user latent factors. The output of this hidden layer is:
\[
\begin{split}
    & l^1_{j} = h(\sum_{i \in nodes(l^0) + 1} W^0_{ji} \; l^0_{i}), \qquad \forall{j \in nodes(l^1)}\\[5pt]
    & \mathbf{l^1} = h(W^{0}\mathbf{l}^{0}), \qquad \text{in vector notation}
\end{split}
\]
where $h(\cdot)$ is a linear activation function of the hidden layer and $W^0$ is a weight matrix of shape $(|ConditionVector|+1) \times K$ (the additional dimension denotes the bias unit with value 1). The same stands for layers $l^1$ and $l^2$ where the latter is the output of the network denoting a generated user profile.
\begin{equation}
    \begin{split}
        & l^2_{k} = g(\sum_{j \in nodes(l^1)+1} W^1_{kj} \; l^1_{j}), \qquad \forall{k \in nodes(l^2)}\\[5pt]
        & \mathbf{l^{2}} = g(W^{1}\mathbf{l}^{1}), \qquad \text{in vector notation}
    \end{split}
    \label{eq:output_layer_mult}
\end{equation}
where $g(\cdot)$ is the linear activation function for the output layer and $W^1$ is the weight matrix of shape $(K+1) \times |I|$ (the additional dimension denotes the bias unit with value 1).
\begin{figure}[h!]
    \centering
    \includegraphics[width=0.95\textwidth]{model/fully_connected_generator.png}
    \caption{GANMF Generator representing a low-rank MF model. The edges connecting the per-user latent factors to the output layer represent the items latent factors. The bias units are omitted.}
    \label{fig:generator_MF}
\end{figure}

Low-rank MF models aim to factorize a rectangular matrix into two low-rank matrices (in a RS context):
\[
\begin{split}
    \hat{URM} & = \Sigma V \\
    \hat{URM} & \in \mathbb{R}^{|U| \times |I|} \\
    \Sigma & \in \mathbb{R}^{|U| \times K} \\
    V & \in \mathbb{R}^{K \times |I|} \\
    K & \ll |U| \\
    K & \ll |I|
\end{split}
\]
where $\Sigma$ and $V$ are the users' and items' latent factors' matrices respectively and $\hat{URM}$ is an approximation of the URM from which we derive the recommendations for users. We can retrieve a users' predicted profile by selecting a row from $\hat{URM}$ which in itself can be retrieved by:
\begin{equation}
    \hat{URM_{u}} = \Sigma_{u}V
    \label{eq:mf_vector_matrix}
\end{equation}
$\Sigma_{u}$ is the row-vector of size $K$ corresponding to the same row in $\hat{URM}$. One can observe that equation \ref{eq:output_layer_mult} denotes the same vector-matrix multiplication operation as \ref{eq:mf_vector_matrix}.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.95\textwidth]{model/vector-matrix.png}
    \caption{The low-rank matrix factorization model derived from a fully connected neural network.}
    \label{fig:vector_matrix}
\end{figure}

Since we are utilizing only the URM, we are limited to two options in regards to possible conditioning vectors; we can either use the row number in the URM respective to the user or the complete URM row-vector that represents the historical profile of the user. In the former case the generator input is just an integer value in the range $[1-|U|]$. The neural network framework we used to implement GANMF provides a convenient \emph{embedding} layer that performs a table lookup of embedding values from integer values. These embeddings are task-specific and are learned in conjunction with the whole network. A clear advantage of this option is that the number of parameters to be learned by the generator is $\Theta(K\times(|I|+|U|))$, similar to baselines like ALSMF. 

If we choose to use the complete row-vector from the URM of a specific user as conditioning vector, the input dimension of the generator would be $|I|$, just like the output layer dimension. In this case the generator takes the role of an autoencoder and we can use the same arguments to show that this network also can be casted into a low-rank MF approach. We conduct experiments with both of these options in order to understand whether a more detailed historical information can produce better user latent factors.

The generator's job is to fool the discriminator of GANMF. While the discriminator's job is to increase the reconstruction loss of generated user profiles, the generator tries to minimize the reconstruction loss:
\begin{equation}
    \mathcal{L}_{G}(y) = D\big(G(y)\big) + \lambda_{G} \|\Omega^{G}\|^{2}_{2}
\end{equation}
where $G(\cdot)$ and $D(\cdot)$ are the generator and discriminator functions respectively, $y$ is the user conditioning vector, $\lambda_{G}$ is the \emph{$L_{2}$} regularization coefficient and $\Omega^{G}$ is the set of parameters of the generator.

\subsection{Single-sample class conditioning}
\label{sec:ss_class_conditioning}

As stated in section \ref{sec:GANMF}, GANMF at its core is a conditional GAN (cGAN) of the type presented in \cite{mirza2014conditional}. Usually the condition input in a cGAN is a label or class associated with the data sample passed to the generator in order to condition the generation process but also to the discriminator so it can judge the realness of the data sample given the label. Applications of cGAN usually involve datasets with multiple classes where for each single class there are hundreds or thousands of samples from the training set. This allows the discriminator to learn not only the source of the samples it receives but also a relation between the sample and its label.

We experimented with a binary classifier discriminator (as per the original formulation of GAN) where the input was the concatenation of a real/generated profile with the conditioning vector representing the user of the profile. We faced a peculiar problem with this version of GANMF; the user latent factor resulting from the training where very similar with one another and the quality (see evaluations) of the recommendations was very poor. However, considering that for every single user we only have one real historical profile this finding is not a surprise. Generalizing the input-target relation from a single data point per label is highly unlikely.

To alleviate this problem and further improve the accuracy of the recommendations we follow an approach called \emph{feature matching} from \cite{salimans2016improved}. Feature matching is presented as a technique to stabilize the training procedure of GANs and also avoid \emph{mode collapse} (see section \ref{appendiceA}). During training, the generator might trick the discriminator very easily by finding a sample that the discriminator cannot distinguish from the real data and always generate that particular sample or minor variations of it. Usually this single sample need not even be recognizable as a meaningful data point in comparison with the dataset at hand (e.g. if generating images of handwritten digits the output of the generator could be a tower in a black background which might resemble the digit one and hence the reason the discriminator cannot distinguish it but is entirely not related to what we are expecting from the generator). Feature matching changes the objective of the generator to not deceive the discriminator but match real data statistics by using the following loss term:
\[
\Big\|\E_{\textbf{x} \sim{p_{data}}} \textbf{f}(\textbf{x}) - \E_{\textbf{z} \sim{p_{z}(\textbf{z})}} \textbf{f}\big(G(\textbf{z})\big)\Big\|^2_{2}
\]
where $\textbf{f}(\cdot)$ is the activation of an intermediate layer of the discriminator, $G(\cdot)$ is the generator function, and $||\cdot||^2_{2}$ is the Euclidean norm squared.

We incorporate this technique in GANMF as a way to enforce conditioning the generating process. The conditioning vector in GANMF is necessary for the generator in order to retrieve the user latent factors. However, the generating process could still be stuck by discarding the information in the conditioning vector and by finding a specific user profile that deceives the GANMF discriminator (when reconstructed in the discriminator, the loss is the same as the average loss of all real user profiles). To force the generator to learn user-specific latent features we change the previous loss of the generator to the following:
\begin{equation}
    \mathcal{L}_{G}(x, y) = \beta \, D\big(G(y)\big) \,+\, (1-\beta) \,\Big\| \, l^1(x) - l^1\big(G(y)\big) \,\Big\|^2_{2} + \lambda_{G} \|\Omega^{G}\|^{2}_{2}
    \label{eq:generator_loss_feature}
\end{equation}
where $l^1$ is the activation of the hidden layer of the autoencoder (discriminator, see section \ref{sec:GANMF_D}), $D(\cdot)$ and $G(\cdot)$ are the discriminator and generator functions respectively, $x$ and $y$ are a real user profile and the corresponding conditioning vector respectively and $\beta$ is a weighting term that decides the balance of the generator between deceiving the generator and matching the hidden layer activations. The last terms is the $L_{2}$ regularization term of parameters $\Omega^{G}$ of the generator controlled by the coefficient $\lambda_{G}$.

The second term of $\mathcal{L}_{G}$ takes the form of another autoencoder incorporating the generator and the encoder part of the discriminator. Given real user profile $x$ and its corresponding conditioning vector $y$ we first retrieve the hidden layer activation of the discriminator for $x$, $l^1(x)$. Then we generate a plausible user profile for $y$, $G(y)$. We retrieve the hidden layer activation of the discriminator for $G(y)$, $l^1(G(y))$. If the generated profile is indeed suitable for the user denoted by $y$ then we should have that $l^1(x)$ and $l^1(G(y)$ must be close to each other by some distance metric (here we use the Euclidean distance squared as \cite{salimans2016improved}).

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{model/full_GANMF.png}
    \caption{Architecture of GANMF: variant where the conditioning vector $y$ represents the row number of a user in the URM.}
    \label{fig:full_ganmf}
\end{figure}

\section{Training}
\subsection{Update rules}
\label{sec:partial_derivatives}
Figure \ref{fig:full_ganmf} depicts the full GANMF model. Since we are using the vector-training approach from CFGAN, we can bypass the policy-gradient based reinforcement learning used by IRGAN and train the complete model end-to-end by Gradient Descent (GD) \cite{rumelhart1986learning}. The update rule for GD is given by:

\begin{equation}
    w^{k+1} = w^{k} - \mu \frac{\partial\mathcal{L}}{\partial w^{k}}
\end{equation}
where $w^{k}$ are the parameters of the model at time $k$, $\mu$ is the \emph{learning rate} and $\mathcal{L}$ is the loss function the model is trying to optimize. The update rule of GD is identical for every neural network, what changes is the partial derivative of the loss function. Among the variations of gradient descent we use \emph{minibatch} GD since it allows for higher degree of parallelism compared to \emph{stochastic} GD and in this way we can make use of graphical processing units (GPUs) for training. 

The discriminator network of GANMF is composed of an autoencoder incorporating two parts, the encoder and decoder models. The functions denoted by each of them for a user profile $\mathbf{x}$ (a column vector) are the followings (in vector notation):

\[
\begin{split}
    Enc(\mathbf{x}) & = h(\mathbf{b}^{E} + \Theta^{E} \mathbf{x}) \\
    Dec\big(Enc(\mathbf{x})\big) & = g\big(\mathbf{b}^{D} + \Theta^{D}Enc(\mathbf{x})\big) \\
    & = g\Big(\mathbf{b}^{D} + \Theta^{D}\big(h(\mathbf{b}^{E} + \Theta^{E} \mathbf{x})\big)\Big)
\end{split}
\]
where $\mathbf{b}^{E}$ and $\mathbf{b}^{D}$ are the encoder and decoder bias vectors respectively, $\Theta^{E}$ and $\Theta^{D}$ are the encoder and decoder parameters respectively and $h\cdot$ and $g(\cdot)$ are activation functions. For $h(\cdot)$ and $g(\cdot)$ we test different functions between \emph{linear}, \emph{sigmoid}, \emph{tanh}, \emph{ReLU} \cite{glorot2011deep} and \emph{LeakyReLU} \cite{maas2013rectifier}.

Given as input a batch of real profiles \textbf{x} and conditioning vectors \textbf{y}, the value of the loss $\mathcal{L}_{D}$ (\ref{eq:dloss}) is:

\[
    \begin{split}
        \mathcal{L}_{D}(\mathbf{x}, \mathbf{y}) = \frac{1}{|B|} \sum_{i \in B}
        & \Bigg[ \Big\|Dec\big(Enc(\mathbf{x}_{i})\big) - \mathbf{x}_{i}\Big\|^{2}_{2} \, + \\
        & \max \Bigg(0, m - \bigg\|Dec\Big(Enc\big(G(\mathbf{y}_{i})\big)\Big) - G(\mathbf{y}_{i})\bigg\|^{2}_{2}\Bigg) \Bigg]
    \end{split}
\]

We now give the partial derivatives of $\mathcal{L}_{D}$ for bias and parameters of both encoder and decoder. In order for the reader to follow easier the derivations we compute separately the partial derivatives for the 2 terms of the summation:

\[
\mathcal{L}_{D} = \frac{1}{|B|} \sum_{i \in B} A + B
\]

\vspace{10pt}

\[
\frac{\partial \mathcal{L}_{D}}{\partial \{ \mathbf{b}^{D}, \mathbf{b}^{E}, \Theta^{D}, \Theta^{E}\}} = \frac{1}{|B|} \sum_{i \in B} \frac{\partial}{\partial \{ \mathbf{b}^{D}, \mathbf{b}^{E}, \Theta^{D}, \Theta^{E}\}} (A + B)
\]

\[
    \begin{split}
        \frac{\partial}{\partial \mathbf{b}^{D}} A
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big) \frac{\partial}{\partial \mathbf{b}^{D}}  Dec\big(Enc(\mathbf{x}_i)\big) \\[10pt]
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big) \, g'\Big(\mathbf{b}^{D} + \Theta^{D}\big(Enc(\mathbf{x}_{i})\big)\Big)
    \end{split}
\]

\vspace{10pt}

\[
    \begin{split}
        \frac{\partial}{\partial \mathbf{b}^{D}} B
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg) \frac{\partial}{\partial \mathbf{b}^{D}} Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) & otherwise
        \end{cases} \\[10pt]
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg) \, g'\bigg(\mathbf{b}^{D} + \Theta^{D}\Big(Enc\big(G(\mathbf{y}_{i})\big)\Big)\bigg) & otherwise
        \end{cases}
    \end{split}
\]

\vspace{10pt}

\[
    \begin{split}
        \frac{\partial}{\partial \mathbf{b}^{E}} A
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big) \frac{\partial}{\partial \mathbf{b}^{E}}  Dec\big(Enc(\mathbf{x}_i)\big) \\[10pt]
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big) \, g'\Big(\mathbf{b}^{D} + \Theta^{D}\big(Enc(\mathbf{x}_{i})\big)\Big) \frac{\partial}{\partial \mathbf{b}^{E}} \Theta^{D} Enc(\mathbf{x}_{i})\\[10pt]
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big) \, g'\Big(\mathbf{b}^{D} + \Theta^{D}\big(Enc(\mathbf{x}_{i})\big)\Big) \Theta^{D} h'(\mathbf{b}^{E} + \Theta^{E}\mathbf{x}_{i})
    \end{split}
\]

\vspace{10pt}

\[
    \begin{split}
        \frac{\partial}{\partial \mathbf{b}^{E}} B
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg) \frac{\partial}{\partial \mathbf{b}^{E}} Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) & otherwise
        \end{cases} \\[10pt]
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg) \, \\ \;\, \cdot \, g'\bigg(\mathbf{b}^{D} + \Theta^{D}\Big(Enc\big(G(\mathbf{y}_{i})\big)\Big)\bigg) \frac{\partial}{\partial \mathbf{b}^{E}} \Theta^{D} Enc\big(G(\mathbf{y}_{i})\big)& otherwise
        \end{cases}\\[10pt]
        & = 
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg) \, \\ \;\, \cdot \, g'\bigg(\mathbf{b}^{D} + \Theta^{D}\Big(Enc\big(G(\mathbf{y}_{i})\big)\Big)\bigg) \Theta^{D} h'\big(\mathbf{b}^{E} + \Theta^{E}G(\mathbf{y}_{i})\big) & otherwise
        \end{cases}
    \end{split}
\]

The partial derivative of both A and B (both column vectors) with respect to matrices $\Theta^{D}$ and $\Theta^{E}$ cannot be written in a matrix form so we show the partial derivatives of each element of A and B:

\[
\begin{split}
    \frac{\partial}{\partial \Theta^{D}_{kl}} A_{j} 
    & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big)_{j} \:\: \frac{\partial}{\partial \Theta^{D}_{kl}}  \Big(Dec\big(Enc(\mathbf{x}_i)\big)\Big)_{j} \\[10pt]
    & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big)_{j} \:\: g'\Big(\mathbf{b}^{D} + \Theta^{D}\big(Enc(\mathbf{x}_{i})\big)\Big)_{j}
    \: \delta_{jk} Enc(\mathbf{x}_{i})_{l}
\end{split}
\]
where $\delta_{ij}$ is the Kronecker delta with:
\[
\delta_{ij} = 
    \begin{cases}
    0 & i \neq j\\
    1 & i = j
    \end{cases}
\]

\vspace{10pt}

In a similar fashion:

\[
    \begin{split}
        \frac{\partial}{\partial \Theta^{D}_{kl}} B_{j}
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg)_{j} \:\: \frac{\partial}{\partial \Theta^{D}_{kl}} Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big)_{j} & otherwise
        \end{cases} \\[10pt]
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg)_{j}\\
            \:\: \cdot g'\bigg(\mathbf{b}^{D} + \Theta^{D}\Big(Enc\big(G(\mathbf{y}_{i})\big)\Big)\bigg)_{j} \:\: \delta_{jk} Enc\big(G(\mathbf{y}_{i})\big)_{l} & otherwise
        \end{cases}
    \end{split}
\]

\vspace{10pt}

\[
    \begin{split}
        \frac{\partial}{\partial \Theta^{E}_{kl}} A_{j}
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big)_{j} \:\: \frac{\partial}{\partial \Theta^{E}_{kl}}  \Big(Dec\big(Enc(\mathbf{x}_i)\big)\Big)_{j} \\[10pt]
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big)_{j} \:\: g'\Big(\mathbf{b}^{D} + \Theta^{D}\big(Enc(\mathbf{x}_{i})\big)\Big)_{j} \:\: \frac{\partial}{\partial \Theta^{E}_{kl}} \Theta^{D} Enc(\mathbf{x}_{i})\\[10pt]
        & = 2 \Big(Dec\big(Enc(\mathbf{x}_i)\big) - \mathbf{x}_{i}\Big)_{j} \:\: g'\Big(\mathbf{b}^{D} + \Theta^{D}\big(Enc(\mathbf{x}_{i})\big)\Big)_{j} \:\: \Theta^{D} h'(\mathbf{b}^{E} + \Theta^{E}\mathbf{x}_{i})_{j} \: \delta_{jk} (\mathbf{x}_{i})_{l}
    \end{split}
\]

\vspace{10pt}

\[
    \begin{split}
        \frac{\partial}{\partial \Theta^{E}_{kl}} B_{j}
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg)_{j} \:\: \frac{\partial}{\partial \Theta^{E}_{kl}} \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big)\bigg)_{j} & otherwise
        \end{cases} \\[10pt]
        & =
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg)_{j} \, \\ \;\, \cdot \, g'\bigg(\mathbf{b}^{D} + \Theta^{D}\Big(Enc\big(G(\mathbf{y}_{i})\big)\Big)\bigg)_{j} \:\: \frac{\partial}{\partial \Theta^{E}_{kl}} \Theta^{D} \Big(Enc\big(G(\mathbf{y}_{i})\big)\Big)_{j}& otherwise
        \end{cases}\\[10pt]
        & = 
        \begin{cases}
            0 & D\big(G(y)\big) \geq m \\
            - 2 \bigg(Dec\Big(Enc\big(G(\mathbf{y}_i)\big)\Big) - G(\mathbf{y}_{i})\bigg)_{j} \, \\ \;\, \cdot \, g'\bigg(\mathbf{b}^{D} + \Theta^{D}\Big(Enc\big(G(\mathbf{y}_{i})\big)\Big)\bigg)_{j} \:\: \Theta^{D} h'\big(\mathbf{b}^{E} + \Theta^{E}G(\mathbf{y}_{i})\big)_{j} \: \delta_{jk} \big(G(\mathbf{y}_{i}\big)_{l} & otherwise
        \end{cases}
    \end{split}
\]

We focus now on the derivation of the update rules for the generator network. The loss function $\mathcal{L}_{G}$ (\ref{eq:generator_loss_feature}) is also composed of two terms so we split this loss too:

\begin{align*}
    &\mathcal{L}_{G}(\mathbf{x}, \mathbf{y}) = \beta \, D\big(G(\mathbf{y})\big) \,+\, (1-\beta) \,\Big\| \, l^1(\mathbf{x}) - l^1\big(G(\mathbf{y})\big) \,\Big\|^2_{2} \\[5pt]
    & \mathcal{L}_{G}(\mathbf{x}, \mathbf{y})= \beta \, \bigg\|Dec\Big(Enc\big(G(\mathbf{y})\big)\Big) - G(\mathbf{y})\bigg\|^{2}_{2} \, + (1 - \beta) \, \Big\|Enc(\mathbf{x}) - Enc\big(G(\mathbf{y})\big)\Big\|^{2}_{2} \\[5pt]
    & \mathcal{L}_{G}(\mathbf{x}, \mathbf{y}) = \beta \, A + (1 - \beta) \, B \\[10pt]
    & \frac{\partial \mathcal{L}_{G}}{\partial \{ \mathbf{b}^{D}, \mathbf{b}^{E}, \Theta^{D}, \Theta^{E}\}} = \frac{1}{|B|} \sum_{i \in B} \beta \, \frac{\partial A}{\partial \{ \mathbf{b}^{D}, \mathbf{b}^{E}, \Theta^{D}, \Theta^{E}\}} + (1 - \beta) \, \frac{\partial B}{\partial \{ \mathbf{b}^{E}, \Theta^{E} \}}
\end{align*}

\vspace{10pt}

One can see that the partial derivatives of $A$ with respect to $\{ \mathbf{b}^{D}, \mathbf{b}^{E}, \Theta^{D}, \Theta^{E}\}$ for $\mathcal{L}_{G}$ is identical to the ones defined for $\mathcal{L}_{D}$ with the only change being that they are computed for the generated profiles instead of the real ones. We give below the partial derivatives of $B$ with respect to the encoder parameters:

\[
\begin{split}
    \frac{\partial B}{\partial \mathbf{b}^{E}} & = 2\Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big) \frac{\partial}{\partial \mathbf{b}^{E}} \Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big) \\[5pt]
    & = 2\Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big) \Big[\frac{\partial}{\partial \mathbf{b}^{E}} Enc(\mathbf{x}_{i}) - \frac{\partial}{\partial \mathbf{b}^{E}} Enc\big(G(\mathbf{y}_{i})\big)\Big] \\[5pt]
    & = 2\Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big) \Big[\big(h'(\mathbf{b}^{E} + \Theta^{E}\mathbf{x}_{i}) - h'\big(\mathbf{b}^{E} + \Theta^{E}G(\mathbf{y}_{i}) \big)\Big]
\end{split}
\]

\vspace{10pt}

\[
\begin{split}
    \frac{\partial}{\partial \Theta^{E}_{kl}} B_{j} 
    & = 2\Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big)_{j} \:\: \frac{\partial}{\partial \Theta^{E}_{kl}} \Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big)_{j} \\[5pt]
    & = 2\Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big)_{j} \:\: \Big[\frac{\partial}{\partial \Theta^{E}_{kl}} Enc(\mathbf{x}_{i})_{j} - \frac{\partial}{\partial \Theta^{E}_{kl}} Enc\big(G(\mathbf{y}_{i})\big)_{j}\Big] \\[5pt]
    & = 2\Big(Enc(\mathbf{x}_{i}) - Enc\big(G(\mathbf{y}_{i})\big)\Big)_{j} \:\: \Big[h'(\mathbf{b}^{E} + \Theta^{E}\mathbf{x}_{i})_{j} \, \delta_{jk}(\mathbf{x}_{i})_{l} - h'\big(\mathbf{b}^{E} + \Theta^{E}G(\mathbf{y}_{i})\big)_{j} \, \delta_{jk}\big(G(\mathbf{y}_{i})\big)_{l}\Big]
\end{split}
\]

\vspace{5pt}

\subsection{Early Stopping}
Early stopping is a regularization technique that helps prevent \emph{overfitting} \cite{yao2007early}. When training machine learning models, given enough expressiveness the model can learn the training data perfectly thus being able to reduce the loss to its minimum value. However when such fully trained models are used in inference phase their performance drops. This phenomenon is termed overfitting and when it occurs the model's generalization ability suffers since it learns to memorize the training data and their noise. Early stopping is a simple mechanism used to stop the training operation before it reaches the overfitting of the model. The metrics by which the training is stopped are the sames ones used for evaluating the final model but they are computed during the training phase on a validation set. If the loss on the training set is dropping and hence the performance is increasing but in the same time the performance of the model on the validation set starts to increase then we have reached the stopping point of the training. A by-product of early stopping is a reduction on the total wall time of the training process especially if the evaluation process is not very expensive and more importantly during hyperparameter tuning. Suppose we were to run training for 100 epochs with early stopping executed every 5 epochs with 2 consecutive worse validation scores and the process is stopped after 40 epochs. This means that on epoch 30 the validation score has registered its highest value. On epoch 35 the validation score has been lower than the one registered on epoch 30. On epoch 40, for a second time, the validation score has been lower than the best registered validation score and the training is stopped. The final model is the one denoted by the parameters of the highest validation score. In this way we stopped the training process midway and saved the time it would take to train fully and with worse performance (figure \ref{fig:earlystopping}). We use early stopping in our training procedure and experiment with different configurations in terms of frequency of early stopping evaluation and number of consecutive worse evaluations allowed.

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{model/EarlyStopping.png}
    \caption{A depiction of the effect of early stopping on training. The dataset used is Movielens 100K, trained fully for 100 epochs and evaluated with MAP@5. The single blue dot represents the test set performance of the model trained with early stopping and the single red dot the test set performance without early stopping. We can see that the performance of training w/o early stopping continues improving until around epoch 60. However, if we were to train the model with early stopping we would have stopped before epoch 40 because the performance on the validation set after this point ceases to improve thus saving wall time when training and also making sure the final model is one that most probably will have higher performance on a holdout set.}
    \label{fig:earlystopping}
\end{figure}


The updating of the discriminator and generator is done according to the vanilla GAN implementation; first we update the parameters of the discriminator and then the parameters of the generator. Algorithm \ref{alg:ganmf} details the steps of the training procedure.

\vspace{10pt}
\begin{algorithm}[H]
    % \algsetup{linenosize=\tiny}
    \footnotesize
    \linespread{1.25}\selectfont
    \label{alg:ganmf}
    \caption{GANMF Training}
    \SetAlgoLined
    \DontPrintSemicolon
    
    \SetKwInOut{Input}{Input}
    \SetKwInOut{Output}{Output}
    \SetKwData{URMtrain}{$URM_{tr}$}
    \SetKwData{URMval}{$URM_{val}$}
    \SetKwData{Batch}{B}
    \SetKwData{Gen}{G}
    \SetKwData{Dis}{D}
    \SetKwData{Margin}{m}
    \SetKwData{Beta}{$\beta$}
    \SetKwData{Dlr}{$\mu_{D}$}
    \SetKwData{Glr}{$\mu_{G}$}
    \SetKwData{Enc}{$Enc$}
    \SetKwData{Dec}{$Dec$}
    \SetKwData{be}{$\mathbf{b}^{E}$}
    \SetKwData{bd}{$\mathbf{b}^{D}$}
    \SetKwData{thetae}{$\Theta^{E}$}
    \SetKwData{thetad}{$\Theta^{D}$}
    \SetKwData{wzero}{$W^{0}$}
    \SetKwData{wone}{$W^{1}$}
    \SetKwData{fake}{fakeProfiles}
    \SetKwData{real}{realProfiles}
    \SetKwData{U}{U}
    \SetKwData{Dloss}{$\mathcal{L}_{D}$}
    \SetKwData{Gloss}{$\mathcal{L}_{G}$}
    \SetKwData{pBE}{$\frac{\partial \Dloss}{\partial \be}$}
    \SetKwData{pBD}{$\frac{\partial \Dloss}{\partial \bd}$}
    \SetKwData{pTE}{$\frac{\partial \Dloss}{\partial \thetae}$}
    \SetKwData{pTD}{$\frac{\partial \Dloss}{\partial \thetad}$}
    \SetKwData{pWzero}{$\frac{\partial \Gloss}{\partial \wzero}$}
    \SetKwData{pWone}{$\frac{\partial \Gloss}{\partial \wone}$}
    \SetKwData{u}{$u$}
    \SetKwData{Iter}{iter}
    \SetKwData{NumIters}{numIterations}
    \SetKwData{Break}{\textbf{break}}
    \SetKwData{Perf}{performance}
    \SetKwData{AllowedWorse}{allowedWorse}
    \SetKwData{Noworse}{noWorse}
    \SetKwData{BestMAP}{bestMAP}
    \SetKwFunction{InitVars}{initialize}
    \SetKwFunction{Fix}{fix}
    \SetKwFunction{Sample}{sampleBatch}
    \SetKwFunction{Generate}{generateBatchProfiles}
    \SetKwFunction{Compute}{compute}
    \SetKwFunction{Update}{update}
    \SetKwFunction{Isworse}{isWorse}
    \SetKwFunction{Evaluate}{evaluate}
    
    \Input{set of users \U, training \URMtrain, validation \URMval, margin \Margin, reconstruction coefficient \Beta, \Dis learning rate \Dlr, \Gen learning rate \Glr, batch size \Batch, early stopping \AllowedWorse}
    \Output{trained \Gen model that can generate historical user profiles}
    
    \BlankLine\BlankLine
    \InitVars{\be, \bd, \thetae, \thetad, \wzero, \wone} \;
    \Noworse $\leftarrow$ 0 \;
    \NumIters $\leftarrow$ $\frac{|U|}{|\Batch|}$ \;
    \While{stopping condition not met}{
        \For{\Iter in \NumIters}{
            \tcp{Discriminator learning}
            
            \u $\leftarrow$ \Sample{\U} \;
            \fake $\leftarrow$ \Generate{\u} \;
            \real $\leftarrow$ \URMtrain[\u] \;
            \Dloss $\leftarrow$ \Compute{\real, \fake} (eq. \ref{eq:dloss}) \;
            \pBE, \pBD, \pTE, \pTD $\leftarrow$ \Compute{\Dloss, \be, \bd, \thetae, \thetad} \;
            % \be $\leftarrow$ \be $-$ \Dlr \pBE \;
            % \bd $\leftarrow$ \bd $-$ \Dlr \pBD \;
            % \thetae $\leftarrow$ \thetae $-$ \Dlr \pTE \;
            % \thetad $\leftarrow$ \thetad $-$ \Dlr \pTD \;
            \be, \bd, \thetae, \thetad $\leftarrow$ \Update{\be, \bd, \thetae, \thetad, \pBE, \pBD, \pTE, \pTD, \Dlr} (section \ref{sec:partial_derivatives})\;
            
            \BlankLine\BlankLine
            \tcp{Generator learning}
            
            % \Fix{\be, \bd, \thetae, \thetad} \;
            \u $\leftarrow$ \Sample{\U} \;
            \fake $\leftarrow$ \Generate{\u} \;
            \real $\leftarrow$ \URMtrain[\u] \;
            \Gloss $\leftarrow$ \Compute{\real, \fake} (eq. \ref{eq:generator_loss_feature}) \;
            \pWzero, \pWone $\leftarrow$ \Compute{\Gloss, \wzero, \wone} \;
            % \wzero $\leftarrow$ \wzero $-$ \Glr \pWzero \;
            % \wone $\leftarrow$ \wone $-$ \Glr \pWone \;
            \wzero, \wone $\leftarrow$ \Update{\wzero, \wone, \pWzero, \pWone, \Glr} \;
        }
    
        \BlankLine\BlankLine
        
        \tcp{Early Stopping}
        \Perf $\leftarrow$ \Evaluate{\Gen, \URMval} \;
        \eIf{\Isworse{\BestMAP, \Perf}}{\Noworse $++$}{\BestMAP = \Perf \; \Noworse $\leftarrow$ 0 \;}
        \If{\Noworse $>$ \AllowedWorse}{\Break}
    }
\end{algorithm}
% For $g(\cdot)$ we follow a more principled approach. Real user profiles are high dimensional and very sparse. This affects the training procedure a lot because the autoencoder might be stuck in a non-optimal trivial solution such as reconstructing a 0-vector. Considering the high degree of sparsity using the \emph{mean squared error} (MSE) loss reduced a lot the reconstruction for the ones in the reconstructed user profile.
